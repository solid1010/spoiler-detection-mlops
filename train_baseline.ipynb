{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7365bc-1d67-4247-823e-c7ec8caa2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score , f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de561173-4f53-47ac-8e90-5e8774cfd71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/10 00:59:10 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/10 00:59:10 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/10 00:59:10 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/10 00:59:10 INFO mlflow.tracking.fluent: Experiment with name 'Spoiler_Detection_Baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/alperen/Desktop/spoiler-detection-mlops/mlruns/1', creation_time=1765317550175, experiment_id='1', last_update_time=1765317550175, lifecycle_stage='active', name='Spoiler_Detection_Baseline', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Spoiler_Detection_Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52566d1b-c2fd-44c3-83fe-bb58f956781a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading...\n",
      "TF-IDF vectorization is being performed...\n",
      "Model is training(Logistic Regression)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/10 14:28:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---RESULTS---\n",
      "Accuracy: 0.6900\n",
      "F1 Score: 0.6946\n",
      "\n",
      "Model ve metrics saved to MLflow successfully!\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Data loading...\")\n",
    "    try:\n",
    "        #DVC ile çekmeye çalıştığımız veri\n",
    "        df = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "    except FileNotFoundError:\n",
    "            print(\"Error: cleaned_data.csv couldn't found! Have to do data cleaning first.\")\n",
    "            \n",
    "\n",
    "    df = df.dropna(subset=[\"cleaned_review_text\",\"label\"])\n",
    "    X = df[\"cleaned_review_text\"]\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)\n",
    "\n",
    "    # TF-IDF Dönüşümü (Metni Sayıya Çevir)\n",
    "    print(\"TF-IDF vectorization is being performed...\")\n",
    "    \n",
    "    # max_features=5000: En önemli 5000 kelimeyi al\n",
    "    tfidf = TfidfVectorizer(max_features=5000)\n",
    "    X_train_vec = tfidf.fit_transform(X_train)\n",
    "    X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "    # Parametreleri Logla\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"max_features\", 5000)\n",
    "\n",
    "\n",
    "    # Modeli Eğit\n",
    "    print(\"Model is training(Logistic Regression)...\")\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Tahmin ve değerlendirme\n",
    "    predictions = model.predict(X_test_vec)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "\n",
    "    print(f\"\\n---RESULTS---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Metrikleri MLflow'a Kaydet\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    # Modeli MLflow'a kaydet\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    print(\"\\nModel ve metrics saved to MLflow successfully!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e49044-7442-46fb-a2ba-903f5a05ab12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
