{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e117f410-f3e9-458a-9885-805664686192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5cb5c2f-36df-4e65-9a86-581a227e3e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total raw data: 573913\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/IMDB_reviews.json\"\n",
    "\n",
    "# With lines=True, we read line by line (json lines), not a single json object\n",
    "try:\n",
    "    df = pd.read_json(data_path,lines=True)\n",
    "except:\n",
    "    df = pd.read_json(data_path)\n",
    "\n",
    "print(f\"Total raw data: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0e77a8-f76d-4648-8beb-6e51bde8ab94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        review_date   movie_id    user_id  is_spoiler  \\\n",
      "0  10 February 2006  tt0111161  ur1898687        True   \n",
      "1  6 September 2000  tt0111161  ur0842118        True   \n",
      "2     3 August 2001  tt0111161  ur1285640        True   \n",
      "3  1 September 2002  tt0111161  ur1003471        True   \n",
      "4       20 May 2004  tt0111161  ur0226855        True   \n",
      "\n",
      "                                         review_text  rating  \\\n",
      "0  In its Oscar year, Shawshank Redemption (writt...      10   \n",
      "1  The Shawshank Redemption is without a doubt on...      10   \n",
      "2  I believe that this film is the best story eve...       8   \n",
      "3  **Yes, there are SPOILERS here**This film has ...      10   \n",
      "4  At the heart of this extraordinary movie is a ...       8   \n",
      "\n",
      "                                  review_summary  \n",
      "0  A classic piece of unforgettable film-making.  \n",
      "1     Simply amazing. The best film of the 90's.  \n",
      "2               The best story ever told on film  \n",
      "3                     Busy dying or busy living?  \n",
      "4         Great story, wondrously told and acted  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94ea550e-fc6f-43e1-97a5-b252d1303e66",
   "metadata": {},
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc620a4-d468-489d-809f-4916e656788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_spoiler\n",
      "False    422989\n",
      "True     150924\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['is_spoiler'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d618d74-9a24-4251-9b11-6bb0259b5f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering: 'review_summary' and 'review_text' combined successfully!\n"
     ]
    }
   ],
   "source": [
    "# The 'review_summary' often contains the most critical spoilers or sentiment.\n",
    "# We combine it with the main text to give the model more context.\n",
    "\n",
    "# Fill NaN values with empty strings to avoid errors\n",
    "df['review_summary'] = df['review_summary'].fillna('')\n",
    "df['review_text'] = df['review_text'].fillna('')\n",
    "\n",
    "# Create a new column: \"Summary. Review Text\"\n",
    "df['combined_text'] = df['review_summary'] + \". \" + df['review_text']\n",
    "\n",
    "print(\"Feature Engineering: 'review_summary' and 'review_text' combined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1770b6fa-8cda-4c99-9bcf-7c5a1322962b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Remaining: ['is_spoiler', 'review_text', 'rating', 'review_summary', 'combined_text']\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "cols_to_drop=[\"movie_id\",\"user_id\",\"review_date\"]\n",
    "\n",
    "df = df.drop(columns=cols_to_drop,errors=\"ignore\") # with errors=ignore, it won't raise an error if columns don't exist, it continues\n",
    "\n",
    "print(\"Columns Remaining:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9ba14c-97f0-4414-99b8-e9fdf562e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Dataset Size: 50000\n"
     ]
    }
   ],
   "source": [
    "# Handling data imbalance (Undersampling)\n",
    "\n",
    "sample_size = 25000\n",
    "\n",
    "spoiler_count = df[df[\"is_spoiler\"]==True].shape[0]\n",
    "# If there aren't as many spoilers as the selected sample size, adjust sample size based on max existing spoilers\n",
    "if spoiler_count < sample_size:\n",
    "    sample_size = spoiler_count\n",
    "\n",
    "spoilers = df[df[\"is_spoiler\"]==True].sample(sample_size,random_state=35)\n",
    "non_spoilers = df[df[\"is_spoiler\"]==False].sample(sample_size,random_state=35)\n",
    "\n",
    "# Concatenate and Shuffle the dataset\n",
    "df_balanced = pd.concat([spoilers, non_spoilers])\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Balanced Dataset Size: {len(df_balanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b8bd52-0ad3-4956-a15a-d7838b20b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of common English contractions to expand\n",
    "# This helps the model understand that \"won't\" means \"will not\", preserving the negative context.\n",
    "contractions = {\n",
    "    \"won't\": \"will not\", \"can't\": \"cannot\", \"i'm\": \"i am\", \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\", \"it's\": \"it is\", \"that's\": \"that is\", \"what's\": \"what is\",\n",
    "    \"n't\": \" not\", \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\",\n",
    "    \"'ve\": \" have\", \"'m\": \" am\", \"idk\": \"i do not know\", \"tbh\": \"to be honest\"\n",
    "}\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # 2. Expand Contractions (NEW STEP)\n",
    "    # Iterate through the dictionary and replace contractions with full words\n",
    "    for contraction, expansion in contractions.items():\n",
    "        if contraction in text:\n",
    "            text = text.replace(contraction, expansion)\n",
    "    \n",
    "    # 3. Remove HTML tags (<br /> etc.) - ESSENTIAL\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    \n",
    "    # 4. Remove square brackets - ESSENTIAL\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "    \n",
    "    # 5. Remove URLs (if any) - GOOD PRACTICE\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    \n",
    "    # NOTE: We intentionally KEEP punctuation! \n",
    "    # DistilBERT needs it to understand context (e.g., '!', '?', ',').\n",
    "    \n",
    "    # 6. Remove extra whitespace and newlines\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aff8f361-7546-4c5e-9378-7fe5d34f6371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning texts...\n",
      "Removed 0 short reviews (noise).\n",
      "Final Data Size after cleaning: 49998\n",
      "                                         review_text  \\\n",
      "0  The comments I've read here pretty much nail h...   \n",
      "1  Mickey Rourke and Marisa Tomei, are absolutely...   \n",
      "2  Since the Chronicles of Narnia are a series of...   \n",
      "3  *****CONTAINS SPOILERS******It took me months ...   \n",
      "4  What a lovely day for Mad Max Fury Road. Not. ...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  peter lorre is finest hour!. the comments i ha...  \n",
      "1  wow........wow..........wow. mickey rourke and...  \n",
      "2  disappointing in the extreme!. since the chron...  \n",
      "3  very intense. *****contains spoilers******it t...  \n",
      "4  mad max fury road: best movie ever or a pile o...  \n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning texts...\")\n",
    "\n",
    "# NOTE: Naming the column \"cleaned_text\" to match the training script expectations\n",
    "# Apply cleaning to the new 'combined_text' column\n",
    "df_balanced[\"cleaned_text\"] = df_balanced[\"combined_text\"].apply(clean_text)\n",
    "\n",
    "# Reviews with fewer than 5 words are usually noise (e.g., \"Good movie\", \"10/10\")\n",
    "# They confuse the model and contribute to underfitting.\n",
    "df_balanced[\"word_count\"] = df_balanced[\"cleaned_text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#---Remove Short Reviews (Noise)---\n",
    "\n",
    "initial_len = len(df_balanced)\n",
    "# Filter out short reviews\n",
    "df_balanced = df_balanced[df_balanced[\"word_count\"] > 2]\n",
    "print(f\"Removed {initial_len - len(df_balanced)} short reviews (noise).\")\n",
    "\n",
    "# Remove duplicates to prevent data leakage\n",
    "df_balanced = df_balanced.drop_duplicates(subset=['cleaned_text'])\n",
    "\n",
    "print(f\"Final Data Size after cleaning: {len(df_balanced)}\")\n",
    "\n",
    "# Check the first few rows to ensure punctuation is preserved\n",
    "print(df_balanced[[\"review_text\", \"cleaned_text\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ddc446-eb49-4fb5-ab1d-4e24eafc6216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for training! High-quality data saved to '../data/cleaned_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding: Convert True/False to 1/0\n",
    "df_balanced[\"label\"] = df_balanced[\"is_spoiler\"].astype(int)\n",
    "\n",
    "# Select only necessary columns to keep the file size optimized\n",
    "output_df = df_balanced[[\"cleaned_text\", \"label\"]] \n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"../data/cleaned_data.csv\"\n",
    "output_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Ready for training! High-quality data saved to '{output_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
